import { component$, useSignal, useStore, useStylesScoped$, useVisibleTask$, $, QRL, Slot, noSerialize } from '@builder.io/qwik';
import { routeLoader$, server$, Form, routeAction$, zod$, z } from '@builder.io/qwik-city';
import { ChatOpenAI } from "@langchain/openai";
import { SystemMessage, HumanMessage, AIMessage } from "@langchain/core/messages";
// Import flag SVGs for each country
import US from 'country-flag-icons/string/3x2/US';
import ES from 'country-flag-icons/string/3x2/ES';
import IT from 'country-flag-icons/string/3x2/IT';
import FR from 'country-flag-icons/string/3x2/FR';
import BR from 'country-flag-icons/string/3x2/BR';
// Import Lucide icons from @qwikest/icons
import {
  LuVolume2,
  LuVolumeX,
  LuMic,
  LuMicOff,
  LuSend,
  LuAlertTriangle
} from '@qwikest/icons/lucide';
// Removed unused useAuthSession import
import { tursoClient } from '~/utils/turso'; // Assuming turso client setup

// --- Interfaces ---
interface ChatMessage {
  role: 'user' | 'assistant' | 'system';
  content: string;
  timestamp?: string;
}

// Maximum number of messages to keep in context window
const MAX_CONTEXT_MESSAGES = 10;

interface FormValues {
  userResponse: string;
  language: string;
}

interface VoiceSettings {
  type: string;
  voice_id: string;
}

// --- Constants ---
const DID_API_URL = import.meta.env.DID_API_URL || "https://api.d-id.com";
// No usamos estas constantes pues usamos server$ para acceder a las claves
// const DID_API_KEY = import.meta.env.DID_API_KEY;
// const OPENAI_API_KEY = import.meta.env.OPENAI_API_KEY;

// Get country code for language
const getLanguageCode = (langCode: string): string => {
  for (const lang of languages) {
    if (lang.value === langCode) {
      return lang.code;
    }
  }
  return 'US'; // Default to US
};
// Define flag SVGs for each language
const flagSvgs = {
  'US': US,
  'ES': ES,
  'IT': IT,
  'FR': FR,
  'BR': BR
};

const languages = [
  { value: "en-US", label: "English", code: 'US', flagSvg: flagSvgs['US'] },
  { value: "es-ES", label: "Spanish", code: 'ES', flagSvg: flagSvgs['ES'] },
  { value: "it-IT", label: "Italian", code: 'IT', flagSvg: flagSvgs['IT'] },
  { value: "fr-FR", label: "French", code: 'FR', flagSvg: flagSvgs['FR'] },
  { value: "pt-BR", label: "Portuguese", code: 'BR', flagSvg: flagSvgs['BR'] },
];

const languageMap: Record<string, string> = {
  'en-US': 'English',
  'es-ES': 'Spanish',
  'it-IT': 'Italian',
  'fr-FR': 'French',
  'pt-BR': 'Portuguese'
};

const voiceMap: Record<string, VoiceSettings> = {
  'en-US': { type: 'microsoft', voice_id: 'en-US-JennyNeural' },
  'es-ES': { type: 'microsoft', voice_id: 'es-ES-AbrilNeural' },
  'it-IT': { type: 'microsoft', voice_id: 'it-IT-IsabellaNeural' },
  'fr-FR': { type: 'microsoft', voice_id: 'fr-FR-DeniseNeural' },
  'pt-BR': { type: 'microsoft', voice_id: 'pt-BR-BrendaNeural' }
};
// --- Helper Functions ---
const getVoiceSettings = (languageCode: string): VoiceSettings => {
  return voiceMap[languageCode] || voiceMap['en-US']; // Default to English
};

const formatRecordingTime = (seconds: number): string => {
  const mins = Math.floor(seconds / 60);
  const secs = seconds % 60;
  return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
};

const processTextForVoice = (text: string): string => {
    if (!text) return "";
    let processed = text.replace(/\*\*([^*]+)\*\*/g, "$1");
    processed = processed.replace(/\*([^*]+)\*/g, "$1");
    processed = processed.replace(/~~([^~]+)~~/g, "$1");
    processed = processed.replace(/`([^`]+)`/g, "$1");
    processed = processed.replace(/```[a-z]*\n([\s\S]*?)```/g, "code block omitted");
    processed = processed.replace(/^#{1,6}\s+(.+)$/gm, "$1");
    processed = processed.replace(/\[([^\]]+)\]\([^)]+\)/g, "$1");
    processed = processed.replace(/https?:\/\/\S+/g, "URL");
    processed = processed.replace(/www\.\S+/g, "URL");
    processed = processed.replace(/\n\s*[-â€¢*+]\s*/g, ", ");
    processed = processed.replace(/\n/g, " ");
    processed = processed.replace(/[#_~<>{}|]/g, "");
    processed = processed.replace(/&[a-z]+;/g, " ");
    processed = processed.replace(/["']([^"']+)["']/g, "$1");
    processed = processed.replace(/\s+/g, " ").trim();
    return processed;
};

// --- Server Functions ---

// IMPORTANT: Replace placeholder API keys with secure server-side access
// (e.g., using requestEv.env.get('DID_SECRET_KEY'))

const getAuthHeader = server$(function() {
    // Fetch the actual key securely on the server
    const apiKey = this.env.get('DID_API_KEY') || import.meta.env.DID_API_KEY; // Use the environment variable you have
    if (!apiKey) {
        console.error("D-ID API Key is not configured on the server.");
        return ''; // Or throw error
    }
    return `Basic ${apiKey}`;
});

const fetchWithRetries = server$(async function(url: string, options: RequestInit, retries = 0): Promise<Response> {
    const MAX_RETRY_COUNT = 3;
    const MAX_DELAY_SEC = 4;
    try {
        console.log(`Server Fetch: Making request to: ${url}`, { method: options.method });
        const response = await fetch(url, options);

        if (!response.ok) {
            const errorText = await response.text().catch(() => 'No error details');
            console.error(`Server Fetch: Request failed status ${response.status}: ${errorText}`);

            if (response.status === 401 || response.status === 403) {
                console.error('Server Fetch: Authentication failed. Check D-ID API key.');
                throw new Error(`Authentication failed: ${response.status}`);
            }

            if (retries < MAX_RETRY_COUNT) {
                const delay = Math.min(Math.pow(2, retries) / 4 + Math.random(), MAX_DELAY_SEC) * 3000;
                console.log(`Server Fetch: Retrying in ${delay}ms...`);
                await new Promise(resolve => setTimeout(resolve, delay));
                // Note: 'this' context might be lost here if not careful. Re-invoking server$ might be needed.
                // For simplicity, direct recursion is shown, but consider implications.
                return fetchWithRetries(url, options, retries + 1);
            }
            throw new Error(`Server Fetch: Request failed status: ${response.status}`);
        }
        return response; // Return the raw Response object
    } catch (error: any) {
        if (retries < MAX_RETRY_COUNT) {
            const delay = Math.min(Math.pow(2, retries) / 4 + Math.random(), MAX_DELAY_SEC) * 3000;
            console.log(`Server Fetch: Request error: ${error.message}, retrying in ${delay}ms...`);
            await new Promise(resolve => setTimeout(resolve, delay));
            return fetchWithRetries(url, options, retries + 1);
        }
        console.error('Server Fetch: Max retries exceeded:', error);
        throw error;
    }
});


const serverInitConnection = server$(async function() {
    console.log("Server: Step 1: Creating a new stream");
    const authHeader = await getAuthHeader();
    if (!authHeader) throw new Error("Server Auth Header failed");

    const response = await fetchWithRetries(`${DID_API_URL}/talks/streams`, {
        method: 'POST',
        headers: {
            'Authorization': authHeader,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            source_url: "https://i.postimg.cc/fLdQq0DW/thumbnail.jpg", // Replace with your avatar image URL if needed
        }),
    });
    const data = await response.json();
    console.log("Server: Stream creation response:", data);
    if (!data.id || !data.session_id) {
        throw new Error("Server: Stream ID or Session ID missing");
    }
    return {
        streamId: data.id,
        offer: data.offer || data.jsep, // Handle potential variations
        iceServers: data.ice_servers,
        sessionId: data.session_id,
    };
});

const serverSendSdpAnswer = server$(async function(streamId: string, sessionId: string, answer: RTCSessionDescriptionInit) {
    console.log("Server: Step 3: Sending SDP answer");
    const authHeader = await getAuthHeader();
     if (!authHeader) throw new Error("Server Auth Header failed");

    const response = await fetchWithRetries(`${DID_API_URL}/talks/streams/${streamId}/sdp`, {
        method: 'POST',
        headers: {
            'Authorization': authHeader,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            answer: answer,
            session_id: sessionId
        })
    });
    if (!response.ok) {
        throw new Error(`Server: SDP response error: ${response.status}`);
    }
    console.log("Server: SDP answer sent successfully");
    return await response.json(); // Or just return success status
});

const serverSendIceCandidate = server$(async function(streamId: string, sessionId: string, candidateData: any) {
    console.log("Server: Sending ICE candidate");
     const authHeader = await getAuthHeader();
     if (!authHeader) throw new Error("Server Auth Header failed");

    const response = await fetchWithRetries(`${DID_API_URL}/talks/streams/${streamId}/ice`, {
        method: 'POST',
        headers: {
            'Authorization': authHeader,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            ...candidateData,
            session_id: sessionId,
        }),
    });
     if (!response.ok) {
        console.error(`Server: Failed to send ICE candidate: ${response.status}`);
        // Don't throw here, as ICE failures can sometimes be recovered
    } else {
        console.log('Server: ICE candidate sent successfully');
    }
});


const serverCreateTalk = server$(async function(text: string, voiceSettings: VoiceSettings, streamId: string, sessionId: string) {
    console.log("Server: Step 4: Creating a talk");
     const authHeader = await getAuthHeader();
     if (!authHeader) throw new Error("Server Auth Header failed");

    const response = await fetchWithRetries(`${DID_API_URL}/talks/streams/${streamId}`, {
        method: 'POST',
        headers: {
            'Authorization': authHeader,
            'Content-Type': 'application/json',
        },
        body: JSON.stringify({
            session_id: sessionId,
            script: {
                type: 'text',
                input: processTextForVoice(text), // Process text server-side too
                provider: {
                    type: voiceSettings.type,
                    voice_id: voiceSettings.voice_id
                }
            },
            config: { stitch: true },
            driver_url: "bank://lively" // Or your specific driver if needed
        })
    });
    if (!response.ok) {
        throw new Error(`Server: Talk request failed status: ${response.status}`);
    }
    const result = await response.json();
    console.log("Server: Talk created successfully:", result);
    return result;
});

const serverCloseStream = server$(async function(streamId: string, sessionId: string) {
    if (!streamId || !sessionId) return;
    console.log("Server: Step 5: Closing the stream");
     const authHeader = await getAuthHeader();
     if (!authHeader) {
         console.error("Server: Cannot close stream, auth header failed");
         return;
     };

    try {
        await fetchWithRetries(`${DID_API_URL}/talks/streams/${streamId}`, {
            method: 'DELETE',
            headers: {
                'Authorization': authHeader,
                'Content-Type': 'application/json',
            },
            body: JSON.stringify({ session_id: sessionId })
        });
        console.log("Server: Stream closed successfully");
    } catch (error: any) {
        console.error("Server: Error closing stream:", error.message);
    }
});

// Function to trim messages to avoid exceeding context window limits
const trimChatHistory = (messages: ChatMessage[], maxMessages: number = MAX_CONTEXT_MESSAGES): ChatMessage[] => {
    if (messages.length <= maxMessages) return [...messages];
    
    // Find system messages (they should always be kept)
    const systemMessages = messages.filter(msg => msg.role === 'system');
    
    // Get the most recent messages, excluding system messages
    const nonSystemMessages = messages.filter(msg => msg.role !== 'system');
    const recentMessages = nonSystemMessages.slice(-maxMessages);
    
    // Combine system messages with recent messages
    return [...systemMessages, ...recentMessages];
};

const serverFetchLangChainResponse = server$(async function(
    userMessage: string,
    threadId: string,
    language: string,
    chatHistory: ChatMessage[] = []
) {
    console.log("Server: Fetching LangChain response for thread:", threadId);
    const openAIApiKey = this.env.get('OPENAI_API_KEY') || import.meta.env.OPENAI_API_KEY;
    
    if (!openAIApiKey) {
        console.error("OpenAI API Key not configured on server.");
        return "Error: AI service not configured.";
    }

    try {
        const llm = new ChatOpenAI({
            openAIApiKey: openAIApiKey,
            model: "gpt-4o-mini",
            temperature: 0
        });

        const systemContent = `You are a helpful assistant for MOVE ON ACADEMY, a Language Academy. Answer all questions to the best of your ability in ${language}.`;
        
        // Add system message if not already present in history
        const hasSystemMessage = chatHistory.some(msg => msg.role === 'system');
        let processedHistory = [...chatHistory];
        
        if (!hasSystemMessage) {
            processedHistory.unshift({
                role: 'system',
                content: systemContent
            });
        }
        
        // Add current user message
        processedHistory.push({
            role: 'user',
            content: userMessage
        });
        
        // Trim history to avoid token limit issues
        const trimmedHistory = trimChatHistory(processedHistory);
        
        // Convert to LangChain message format
        const messages = trimmedHistory.map(msg => {
            if (msg.role === 'system') return new SystemMessage(msg.content);
            if (msg.role === 'user') return new HumanMessage(msg.content);
            return new AIMessage(msg.content);
        });

        console.log(`Server: Using ${messages.length} messages for context`);
        const response = await llm.invoke(messages);
        console.log("Server: LangChain response:", response.content);
        return response.content as string;

    } catch (error: any) {
        console.error("Server: Error in LangChain model:", error);
        return "I'm sorry, I encountered an error processing your request.";
    }
});

const serverProcessAudio = server$(async function(audioBase64: string, mimeType: string, language: string): Promise<string> {
    console.log("Server: Processing audio with OpenAI STT");
    const openAIApiKey = this.env.get('OPENAI_API_KEY');
    if (!openAIApiKey) {
        console.error("OpenAI API Key not configured on server.");
        return "Error: Speech service not configured.";
    }

    try {
        // Convert base64 string back to binary data
        const binaryData = Buffer.from(audioBase64, 'base64');
        
        // Create a new FormData on the server side
        const formData = new FormData();
        
        // Create a Blob from the binary data
        const blob = new Blob([binaryData], { type: mimeType });
        
        // Append the blob with a filename
        formData.append("file", blob, "audio.webm");
        
        // Convertir el nombre del idioma a cÃ³digo ISO-639-1
        let languageCode = "";
        switch (language.toLowerCase()) {
            case "english": languageCode = "en"; break;
            case "spanish": languageCode = "es"; break;
            case "italian": languageCode = "it"; break;
            case "french": languageCode = "fr"; break;
            case "portuguese": languageCode = "pt"; break;
            default: languageCode = "en";
        }
        
        // AÃ±adir el idioma en formato ISO-639-1 a la API de Whisper
        formData.append("language", languageCode);
        
        console.log(`Server: Audio processing - Using language code '${languageCode}' for '${language}'`);
        
        // Mejorar el prompt para proporcionar mÃ¡s contexto basado en el idioma
        formData.append("prompt", `The following is a conversation in ${language}. Please transcribe accurately maintaining the original language.`);
        
        formData.append("model", "whisper-1");
        formData.append("response_format", "text");

        console.log("Server: Sending audio data to OpenAI, size:", binaryData.length, "bytes");
        
        const response = await fetch("https://api.openai.com/v1/audio/transcriptions", {
            method: "POST",
            headers: {
                "Authorization": `Bearer ${openAIApiKey}`,
                // Content-Type is set automatically by fetch for FormData
            },
            body: formData,
        });

        if (!response.ok) {
            const errorData = await response.text();
            console.error("Server: OpenAI STT API error:", response.status, errorData);
            throw new Error(`OpenAI STT API error: ${response.status}`);
        }

        const transcriptionText = await response.text();
        console.log(`Server: Transcription result (${language}):`, transcriptionText);
        console.log(`Server: Transcription length: ${transcriptionText.length} characters`);
        return transcriptionText.trim();

    } catch (error: any) {
        console.error("Server: Error processing audio with OpenAI:", error);
        return "Error processing audio.";
    }
});

const serverSaveChatMessage = server$(async function(sessionId: string, userMessage: string, botResponse: string, userId: string | undefined) {
    if (!userId) {
        console.warn("Server: Cannot save chat message, user not logged in.");
        return;
    }
    console.log("Server: Saving chat message for user:", userId);
    try {
        const client = tursoClient(this); // Pass full request event context
        
        // Check if the chat_history table exists and has the expected columns
        const tableInfo = await client.execute({
            sql: "PRAGMA table_info(chat_history)"
        });
        
        // Log the table structure for debugging
        console.log("Chat history table structure:", tableInfo.rows);
        
        // Get all column names for error handling
        const columnNames = tableInfo.rows.map((row: any) => row.name);
        console.log("Chat history columns:", columnNames.join(', '));
        
        // Verify user_id column exists and handle potential naming issues
        const userIdColumn = tableInfo.rows.find((row: any) =>
            row.name === 'user_id' || row.name === 'userId');
            
        if (!userIdColumn) {
            console.error("Server: chat_history table is missing the user_id/userId column!");
            return;
        }
        
        // Use the actual column name from the database
        const userIdColumnName = userIdColumn.name;
        console.log(`Server: Using column name "${userIdColumnName}" for user ID`);
        
        try {
            // Dynamically build SQL with correct column name
            const insertSQL = `INSERT INTO chat_history (${userIdColumnName}, role, content, timestamp) VALUES (?, ?, ?, ?)`;
            
            // Save user message
            const userResult = await client.execute({
                sql: insertSQL,
                args: [userId, 'user', userMessage, new Date().toISOString()]
            });
            console.log("Server: User message saved successfully", userResult);
            
            // Save assistant message
            const assistantResult = await client.execute({
                sql: insertSQL,
                args: [userId, 'assistant', botResponse, new Date().toISOString()]
            });
            console.log("Server: Assistant message saved successfully", assistantResult);
        } catch (insertError: any) {
            console.error("Server: SQL insert error:", insertError.message);
            if (insertError.message.includes('no column named')) {
                console.error("Server: Column name error - check that column names match exactly with the schema");
                console.error("Server: Available columns:", columnNames.join(', '));
                console.error("Server: Attempted to use column:", userIdColumnName);
            }
            throw insertError; // Re-throw to be caught by outer try/catch
        }
        
        console.log("Server: Chat messages saved successfully");
    } catch (error: any) {
        console.error("Server: Error saving chat message to Turso:", error.message);
        console.error("Server: Error details:", error);
    }
});

const serverUpdateUserLang = server$(async function(userId: string | undefined, lang: string) {
     if (!userId) {
        console.warn("Server: Cannot update language, user not logged in.");
        return;
    }
    console.log("Server: Updating language for user:", userId, "to", lang);
     try {
        const client = tursoClient(this); // Pass full request event context
        // Get table info to check the actual column names
        const tableInfo = await client.execute({
            sql: "PRAGMA table_info(users)"
        });
        
        // Log the table structure for debugging
        console.log("Users table structure:", tableInfo.rows);
        
        // Try to find the chatbot language column (might be chatbotLang or chatbot_lang)
        const langColumnInfo = tableInfo.rows.find((row: any) =>
            row.name.toLowerCase().includes('chatbot') && row.name.toLowerCase().includes('lang'));
        
        if (langColumnInfo) {
            const langColumnName = langColumnInfo.name;
            console.log(`Found language column: ${langColumnName}`);
            
            await client.execute({
                sql: `UPDATE users SET ${langColumnName} = ? WHERE id = ?`,
                args: [lang, userId]
            });
            console.log("Server: User language updated successfully");
        } else {
            console.error("Server: Couldn't find chatbot language column in users table");
        }
    } catch (error: any) {
        console.error("Server: Error updating user language in Turso:", error.message);
    }
});


// Constants for managing context window
// Use the MAX_CONTEXT_MESSAGES constant defined earlier

// Function to load chat history
const serverLoadChatHistory = server$(async function(userId: string | undefined, limit: number = 50) {
    if (!userId) {
        console.warn("Server: Cannot load chat history, user not logged in.");
        return [];
    }
    
    console.log("Server: Loading chat history for user:", userId);
    try {
        const client = tursoClient(this);
        
        // Get most recent conversation thread for this user
        // We'll load in ascending order to get chronological conversation
        const result = await client.execute({
            sql: "SELECT role, content, timestamp FROM chat_history WHERE user_id = ? ORDER BY timestamp ASC LIMIT ?",
            args: [userId, limit * 2] // Double the limit to account for user/assistant pairs
        });
        
        // Group messages by conversation pairs to ensure we have complete exchanges
        const messages = result.rows.map((row: any) => ({
            role: row.role,
            content: row.content,
            timestamp: row.timestamp
        }));
        
        console.log(`Server: Loaded ${messages.length} chat history messages`);
        
        // If we have a lot of messages, trim to latest complete conversations
        if (messages.length > MAX_CONTEXT_MESSAGES) {
            // Keep the most recent complete conversations
            const startIndex = Math.max(0, messages.length - MAX_CONTEXT_MESSAGES);
            // Make sure we don't start in the middle of a conversation pair
            const adjustedIndex = messages[startIndex].role === 'assistant' ? startIndex - 1 : startIndex;
            const trimmedMessages = messages.slice(Math.max(0, adjustedIndex));
            console.log(`Server: Trimmed history from ${messages.length} to ${trimmedMessages.length} messages`);
            return trimmedMessages;
        }
        
        return messages;
    } catch (error: any) {
        console.error("Server: Error loading chat history:", error.message);
        return [];
    }
});

// --- Route Loader ---
export const useInitialData = routeLoader$(async (requestEv) => {
    const session = requestEv.sharedMap.get('session');
    let userLanguage = 'en-US'; // Default
    let userId: string | undefined = undefined;

    // First check for session.user.id
    if (session?.user?.id) {
        userId = session.user.id;
    } else {
        // Fallback to checking the auth_token cookie directly
        const authToken = requestEv.cookie.get('auth_token')?.value;
        if (!authToken) {
            // If no auth token, redirect to login
            console.log("[CHAT] No authentication found, redirecting to login");
            throw requestEv.redirect(302, '/auth/');
        }
        // Use the auth token as the user ID
        console.log("[CHAT] Using auth_token cookie for authentication");
        userId = authToken;
    }
    
    try { // Start try block for DB query
        const client = tursoClient(requestEv); // Pass full request event
        // At this point, userId is guaranteed to be a string (not undefined)
        // because we checked with if (!session?.user?.id) above
        const id = userId as string; // Explicitly cast to string for TypeScript
        
        // Get table info to check actual column names
        const tableInfo = await client.execute({
            sql: "PRAGMA table_info(users)"
        });
        
        // Log the table structure for debugging
        console.log("[CHAT] Users table structure:", tableInfo.rows);
        
        // Try to find the chatbot language column (might be chatbotLang or chatbot_lang)
        const langColumnInfo = tableInfo.rows.find((row: any) =>
            row.name.toLowerCase().includes('chatbot') && row.name.toLowerCase().includes('lang'));
        
        if (langColumnInfo) {
            const langColumnName = langColumnInfo.name;
            console.log(`[CHAT] Found language column: ${langColumnName}`);
            
            // Use a fixed alias in the query to avoid TypeScript dynamic property access issues
            const result = await client.execute({
                sql: `SELECT ${langColumnName} AS chatbot_language FROM users WHERE id = ? LIMIT 1`,
                args: [id]
            });
            
            if (result.rows.length > 0 && result.rows[0].chatbot_language) {
                const langValue = result.rows[0].chatbot_language;
                // Ensure the loaded language is valid
                const validLang = languages.some(l => l.value === langValue);
                if (validLang) {
                    userLanguage = langValue as string;
                } else {
                    console.warn(`[CHAT] Loaded invalid language '${langValue}' for user ${userId}, using default.`);
                }
            }
        } else {
            console.warn("[CHAT] Couldn't find chatbot language column in users table");
        }
    } catch (e: any) { // Catch block for the DB query try
        console.error("[CHAT] Failed to load user language from DB:", e.message);
    } // Closing brace for try block

    return {
        initialLanguage: userLanguage,
        userId: userId,
        // Generate initial thread ID here if not persisting per user
        initialThreadId: crypto.randomUUID()
    };
});


// --- Component ---
export default component$(() => {
    useStylesScoped$(STYLES);
    const initialData = useInitialData();
    // const session = useAuthSession(); // Removed as session object is not used directly

    // --- State Signals & Stores ---
    const streamId = useSignal("");
    const sessionId = useSignal("");
    const connected = useSignal(false);
    const initiating = useSignal(false);
    const loading = useSignal(false); // For AI response/talk generation
    const muteVideo = useSignal(false);
    const connectionError = useSignal<string | null>(null);
    const isRecording = useSignal(false);
    const recordingTime = useSignal(0);
    const threadId = useSignal(initialData.value?.initialThreadId ?? crypto.randomUUID()); // Use optional chaining and default

    const chatHistory = useStore<ChatMessage[]>([]);
    const chatHistoryLoaded = useSignal(false);
    const formValues = useStore<FormValues>({
        userResponse: "",
        language: initialData.value?.initialLanguage ?? 'en-US', // Use optional chaining and default
    });

    // --- Refs ---
    const videoRef = useSignal<HTMLVideoElement>();
    const chatMessagesRef = useSignal<HTMLDivElement>();
    const inputRef = useSignal<HTMLInputElement>();
    const peerConnectionRef = useSignal<any>(null);
    const recorderRef = useSignal<any>(null);
    const timerIntervalRef = useSignal<NodeJS.Timeout | null>(null);
    const statsIntervalIdRef = useSignal<NodeJS.Timeout | null>(null);
    const lastBytesReceivedRef = useSignal(0);
    const videoIsPlayingRef = useSignal(false);
    const connectionTimeoutRef = useSignal<NodeJS.Timeout | null>(null);


    // --- QRL Functions for WebRTC/Component Logic ---

    // Define these functions outside useVisibleTask$ so they can be called by event handlers too

    const setVideoElement$ = $((stream: MediaStream | null) => {
        const video = videoRef.value;
        if (!video) return;

        if (stream) {
            console.log("Setting video stream with tracks:", stream.getTracks().length);
            stream.getTracks().forEach(track => {
                console.log(`Track: ${track.id}, kind: ${track.kind}, state: ${track.readyState}`);
            });
            
            // IMPORTANT: We need to avoid stopping tracks coming from the peer connection
            // as that can cause them to end prematurely
            
            // Only stop tracks if they're not from our WebRTC connection
            if (video.srcObject && !peerConnectionRef.value) {
                try {
                    console.log("Stopping non-WebRTC tracks");
                    (video.srcObject as MediaStream).getTracks().forEach(track => track.stop());
                } catch (err) {
                    console.warn("Error stopping tracks:", err);
                }
            }
            
            // Set the new stream without stopping its tracks
            video.srcObject = stream;
            video.loop = false;
            video.muted = muteVideo.value; // Ensure mute state is respected
            
            // Make sure the video is not hidden
            video.style.visibility = 'visible';
            video.style.display = 'block';
            video.style.display = 'block';
            
            // Play with fallback to muted if needed
            video.play().catch(e => {
                console.error('Error playing stream video:', e);
                if (e.name === 'NotAllowedError') {
                    console.log('Autoplay policy error, trying with muted video');
                    video.muted = true;
                    video.play().catch(e2 => {
                        console.error('Still cannot play stream even with mute:', e2);
                    });
                }
            });
        } else {
            console.log("Clearing video stream");
            if (video.srcObject) {
               (video.srcObject as MediaStream).getTracks().forEach(track => track.stop());
            }
            video.srcObject = null;
            // After clearing, always revert to idle video
            playIdleVideo$(); // Switch to idle when stream is removed - Call the QRL version
        }
    });
const playIdleVideo$ = $(() => {
    // Don't switch to idle if we know we're loading - avatar should appear soon
    if (loading.value || initiating.value) {
        console.log("Not playing idle video while loading or initiating");
        return;
    }

    const video = videoRef.value;
    if (!video) {
        console.error("Cannot play idle video - video element reference is null");
        return;
    }

    console.log("Attempting to play idle video");
    
    // Check if we have an actively playing stream and an active connection
    const pc = peerConnectionRef.value;
    const hasActiveConnection = pc && pc.connectionState === 'connected';
    
    // First, check if we should even switch to idle
    if (hasActiveConnection && video.srcObject instanceof MediaStream) {
        const activeTracks = video.srcObject.getVideoTracks().filter(t => t.readyState === 'live' && !t.muted);
        
        // If we have active live video tracks *with* actual data flowing, don't switch
        if (activeTracks.length > 0 && videoIsPlayingRef.value) {
            console.log("Active video stream with data is playing, not switching to idle");
            return;
        }
        
        console.log("Switching to idle despite connection because stream is inactive");
    }
    
    // At this point, we know we need to switch to idle
    
    // Properly handle WebRTC stream cleanup
    if (video.srcObject instanceof MediaStream) {
        try {
            // Detach tracks from video element first
            const currentTracks = video.srcObject.getTracks();
            
            if (hasActiveConnection) {
                // If we still have an active connection, just detach tracks without stopping
                console.log("Preserving WebRTC tracks while switching to idle");
                currentTracks.forEach(track => {
                    console.log(`Track preserved: ${track.id}, kind: ${track.kind}, state: ${track.readyState}`);
                });
            } else {
                // If connection is gone, we can safely stop all tracks
                console.log("No active connection, safely stopping all tracks");
                currentTracks.forEach(track => {
                    console.log(`Stopping track: ${track.id}, kind: ${track.kind}, state: ${track.readyState}`);
                    track.stop();
                });
            }
        } catch (err) {
            console.warn("Error handling stream tracks:", err);
        }
    }
    
    // If the idle video is already playing properly, don't restart it
    if (video.src &&
        video.src.includes('prs_alice.idle.mp4') &&
        !video.paused &&
        !video.ended &&
        video.readyState >= 3) { // HAVE_FUTURE_DATA or better
        console.log("Idle video already playing correctly, no need to restart");
        return;
    }

    // Clear the srcObject reference (after we've dealt with the tracks)
    video.srcObject = null;
    
    // Reset any previous video state
    video.pause();
    video.removeAttribute('srcObject'); // Ensure srcObject is fully cleared
    video.currentTime = 0;

    // Use a direct, absolute path to the idle video
    const fullVideoPath = window.location.origin + '/prs_alice.idle.mp4';
    console.log("Idle video path:", fullVideoPath);

    // Set properties and force play with a more structured approach
    try {
        // First, clear any previous src to avoid conflicts
        video.removeAttribute('src');
        video.load(); // Important to fully reset video state
        
        // Configure for maximum autoplay compatibility
        video.muted = true; // Force muted initially
        video.loop = true;
        video.style.display = 'block';
        video.autoplay = true;
        video.playsInline = true;
        video.controls = false;
        
        // Set the src and load
        video.src = fullVideoPath;
        video.load(); // Load the new source
        
        console.log("Video configured, attempting to play idle video");
        
        // Play with structured error handling and multiple fallbacks
        const attemptPlay = () => {
            return video.play()
                .then(() => {
                    console.log("Idle video playing successfully");
                    videoIsPlayingRef.value = false; // We're in idle mode
                    
                    // Restore user's mute preference after successful play
                    setTimeout(() => {
                        video.muted = muteVideo.value;
                    }, 300);
                    
                    return true;
                })
                .catch(error => {
                    console.error("Error playing idle video:", error);
                    return false;
                });
        };
        
        // First attempt
        attemptPlay().then(success => {
            if (!success) {
                // First fallback: forced mute + delay
                console.log("Retrying with forced mute after delay");
                video.muted = true;
                
                setTimeout(() => {
                    attemptPlay().then(fallbackSuccess => {
                        if (!fallbackSuccess) {
                            // Final fallback: reload video + forced settings
                            console.log("Final retry with video reload");
                            video.load();
                            video.muted = true;
                            video.autoplay = true;
                            video.currentTime = 0;
                            
                            video.play().catch(finalError => {
                                console.error("All idle video play attempts failed:", finalError);
                            });
                        }
                    });
                }, 500);
            }
        });
    } catch (err) {
        console.error("Exception setting up idle video:", err);
    }
});

    const onVideoStatusChange$ = $((isPlaying: boolean, stream: MediaStream | null) => {
        console.log("Video status change called - isPlaying:", isPlaying, "stream exists:", !!stream);
        
        // If we're in the middle of certain operations, we should defer video changes
        const isProcessing = initiating.value || loading.value;
        
        if (isPlaying && stream) {
            // Verify the stream actually has active video tracks before switching
            const videoTracks = stream.getVideoTracks();
            const hasActiveTracks = videoTracks.length > 0 && videoTracks.some(track => track.readyState === 'live');
            
            console.log(`Stream has ${videoTracks.length} video tracks, active: ${hasActiveTracks}`);
            
            if (hasActiveTracks) {
                console.log("Setting active video stream with live tracks");
                
                // Special handling if we're in a processing state
                if (isProcessing) {
                    console.log("Currently initiating or loading, scheduling stream for later");
                    // Store reference to stream to use when ready, but don't immediately set
                    setTimeout(() => {
                        if (videoRef.value) {
                            console.log("Setting delayed video stream");
                            // Use a safe method to set the video source without stopping existing tracks
                            const video = videoRef.value;
                            
                            // Only replace stream if not already set or if the track IDs changed
                            if (!video.srcObject ||
                                !(video.srcObject instanceof MediaStream) ||
                                video.srcObject.getVideoTracks().length === 0) {
                                
                                console.log("Setting stream with safe transition");
                                video.srcObject = stream;
                                video.muted = muteVideo.value;
                                video.style.display = 'block';
                                
                                video.play().catch(e => {
                                    console.error("Error playing delayed video:", e);
                                    if (e.name === 'NotAllowedError') {
                                        video.muted = true;
                                        video.play().catch(e2 => console.error("Still cannot play video:", e2));
                                    }
                                });
                            } else {
                                console.log("Video already has a valid srcObject, skipping update");
                            }
                        }
                    }, 1000);
                    return;
                }
                
                // Normal flow for setting video stream
                if (videoRef.value) {
                    try {
                        const video = videoRef.value;
                        
                        // CRITICAL: If we had a src URL (from idle video), we need to clear it properly first
                        if (video.src) {
                            video.pause();
                            video.removeAttribute('src');
                            video.load(); // Important to reset the video element
                        }
                        
                        console.log("Setting stream directly to video element");
                        video.srcObject = stream;
                        video.muted = muteVideo.value;
                        video.style.display = 'block';
                        
                        // Force play with retries
                        const playPromise = video.play();
                        if (playPromise !== undefined) {
                            playPromise.catch(e => {
                                console.error('Error playing video:', e);
                                if (e.name === 'NotAllowedError') {
                                    video.muted = true;
                                    video.play().catch(e2 => console.error('Still cannot play video:', e2));
                                }
                            });
                        }
                    } catch (err) {
                        console.error("Error setting video stream:", err);
                    }
                } else {
                    console.warn("Video ref is null, cannot set stream");
                }
            } else {
                console.log("Stream has no active tracks or all tracks ended");
                // Only switch to idle if we're not in the middle of something important
                if (!isProcessing) {
                    console.log("No processing in progress, switching to idle video");
                    playIdleVideo$();
                } else {
                    console.log("Processing in progress, keeping current video state");
                }
            }
        } else {
            // We're explicitly told to play idle video
            if (!isProcessing) {
                console.log("No active stream, playing idle video");
                playIdleVideo$();
            } else {
                console.log("Loading or initiating, not switching to idle video yet");
            }
        }
    });

    const onIceGatheringStateChange$ = $(() => {
        const pc = peerConnectionRef.value;
        if (!pc) return;
        console.log('ICE gathering state:', pc.iceGatheringState);
    });

    const onIceCandidate$ = $(async (event: RTCPeerConnectionIceEvent) => {
        const pc = peerConnectionRef.value;
        if (!event.candidate || !streamId.value || !sessionId.value || !pc) return;
        console.log('ICE candidate:', event.candidate);
        const { candidate, sdpMid, sdpMLineIndex } = event.candidate;
        try {
            await serverSendIceCandidate(streamId.value, sessionId.value, {
                candidate, sdpMid, sdpMLineIndex
            });
        } catch (error) {
            console.error('Client: Failed to send ICE candidate via server:', error);
        }
    });

    const onIceConnectionStateChange$ = $(() => {
        const pc = peerConnectionRef.value;
        if (!pc) return;
        const state = pc.iceConnectionState;
        console.log('ICE connection state:', state);

        if (state === 'connected' || state === 'completed') {
            if (connectionTimeoutRef.value) {
                clearTimeout(connectionTimeoutRef.value);
                connectionTimeoutRef.value = null;
            }
            connected.value = true;
            connectionError.value = null;
            console.log('Connection established successfully');
        } else if (state === 'failed' || state === 'closed' || state === 'disconnected') {
            console.error('ICE connection failed or closed');
            // Attempt cleanup, but avoid recursive connection attempts here
            closePC$(false); // Close without triggering server close yet - Call QRL version
            connected.value = false;
            connectionError.value = 'Connection failed. Please try reconnecting.';
        }
    });

     const onConnectionStateChange$ = $(() => {
        const pc = peerConnectionRef.value;
        if (!pc) return;
        const state = pc.connectionState;
        console.log('Peer connection state:', state);
        if (state === 'connected') {
            connected.value = true;
            connectionError.value = null;
        } else if (state === 'failed' || state === 'closed') {
            connected.value = false;
            connectionError.value = 'Connection failed. Please try reconnecting.';
            closePC$(false); // Call QRL version
        }
    });

    const onSignalingStateChange$ = $(() => {
        const pc = peerConnectionRef.value;
        if (!pc) return;
        console.log('Signaling state:', pc.signalingState);
    });
const onTrack$ = $((event: RTCTrackEvent) => {
    console.log('onTrack event fired:', event);
    const pc = peerConnectionRef.value;
    if (!event.track || !pc) {
        console.log('onTrack: Event received but no valid track or PC found.');
        return;
    }
    
    console.log(`Track received: ${event.track.id}, kind: ${event.track.kind}, state: ${event.track.readyState}`);
    
    // Keep track of all received tracks for debugging
    event.track.addEventListener('ended', () => {
        console.log(`Track ended: ${event.track.id}, kind: ${event.track.kind}`);
    });
    
    // Create a listener for when the track starts actually flowing data
    event.track.addEventListener('unmute', () => {
        console.log(`Track unmuted: ${event.track.id}, kind: ${event.track.kind}`);
        if (event.streams && event.streams.length > 0) {
            // Store the stream directly to avoid garbage collection
            const stream = event.streams[0];
            
            // If this is a video track, try to use it
            if (event.track.kind === 'video' && stream.getVideoTracks().length > 0) {
                console.log('Video stream available after unmute');
                
                // Only set the video src directly if we're not currently in the middle of loading
                // or if we specifically want to show the avatar animation
                if (!loading.value || videoIsPlayingRef.value) {
                    // Directly set to video element to avoid our helper function that might
                    // be stopping tracks inadvertently
                    const video = videoRef.value;
                    if (video) {
                        console.log('Setting unmuted stream directly to video element');
                        
                        // Just set the srcObject directly without stopping tracks
                        video.srcObject = stream;
                        video.style.display = 'block';
                        video.muted = muteVideo.value;
                        
                        video.play().catch(e => {
                            console.error('Error playing unmuted stream:', e);
                            if (e.name === 'NotAllowedError') {
                                video.muted = true;
                                video.play().catch(e2 => {
                                    console.error('Still cannot play unmuted stream:', e2);
                                });
                            }
                        });
                    }
                } else {
                    console.log('Not setting video element yet as we are still loading or waiting for active tracks');
                }
            }
        }
    });

    // Don't clear stats interval - we need it to continuously monitor stream activity
    // But we should clear any existing interval first to avoid duplicates
    if (statsIntervalIdRef.value) {
        clearInterval(statsIntervalIdRef.value);
        statsIntervalIdRef.value = null;
    }

    // Create a more robust stats gathering interval
    statsIntervalIdRef.value = setInterval(async () => {
        if (!pc || pc.connectionState !== 'connected') {
            if (statsIntervalIdRef.value) clearInterval(statsIntervalIdRef.value);
            statsIntervalIdRef.value = null;
            return;
        }
        
        try {
            // Get stats for all receivers instead of just this track
            // This is more reliable especially when tracks change
            const receivers = pc.getReceivers();
            let foundActiveVideo = false;
            let totalBytesReceived = 0;
            
            // First check if we have any active video tracks at all
            const videoTracks = receivers
                .filter((receiver: RTCRtpReceiver) => receiver.track && receiver.track.kind === 'video' && receiver.track.readyState === 'live')
                .map((receiver: RTCRtpReceiver) => receiver.track);
                
            console.log(`Found ${videoTracks.length} active video tracks`);
            
            if (videoTracks.length > 0) {
                // Then get detailed stats for each track
                const stats = await pc.getStats();
                
                stats.forEach((report: RTCStats) => {
                    if (report.type === 'inbound-rtp' && 'mediaType' in report && report.mediaType === 'video') {
                        foundActiveVideo = true;
                        
                        const bytesReceived = 'bytesReceived' in report ? report.bytesReceived as number : 0;
                        totalBytesReceived += bytesReceived;
                        
                        // Consider video actively playing if we're receiving increasing data
                        const isActivelyReceivingData = bytesReceived > lastBytesReceivedRef.value && bytesReceived > 0;
                        const videoStatusChanged = videoIsPlayingRef.value !== isActivelyReceivingData;
                        
                        if (videoStatusChanged) {
                            videoIsPlayingRef.value = isActivelyReceivingData;
                            
                            if (isActivelyReceivingData) {
                                console.log("D-ID video stream now actively receiving data, switching from idle");
                                
                                // Get all tracks to create a complete stream
                                const allTracks = receivers
                                    .filter((receiver: RTCRtpReceiver) => receiver.track && receiver.track.readyState === 'live')
                                    .map((receiver: RTCRtpReceiver) => receiver.track);
                                    
                                // Create a fresh stream with all active tracks
                                const completeStream = new MediaStream(allTracks);
                                
                                // Use our status change handler to update the video
                                onVideoStatusChange$(true, completeStream);
                            } else if (!loading.value) {
                                console.log("D-ID video stream paused, reverting to idle");
                                onVideoStatusChange$(false, null);
                            }
                        }
                        // Store total bytes for next comparison
                        lastBytesReceivedRef.value = totalBytesReceived;
                    }
                });
            }
            
            // Handle case when no active video is found but we thought we were playing
            if (!foundActiveVideo && videoIsPlayingRef.value) {
                console.log("No active video tracks found in stats");
                videoIsPlayingRef.value = false;
                
                // Only switch to idle if we're not in the middle of loading something
                if (!loading.value) {
                    onVideoStatusChange$(false, null);
                }
            }
        } catch (error) {
            console.error('Error getting stats:', error);
        }
    }, 1000);

    console.log("Track handler set up, waiting for active video data before switching from idle");
});

    const closePC$ = $((triggerServerClose = true) => {
        const pc = peerConnectionRef.value;
        if (!pc) return;
        console.log('Client: Closing peer connection');

        pc.removeEventListener('icegatheringstatechange', onIceGatheringStateChange$);
        pc.removeEventListener('icecandidate', onIceCandidate$);
        pc.removeEventListener('iceconnectionstatechange', onIceConnectionStateChange$);
        pc.removeEventListener('connectionstatechange', onConnectionStateChange$);
        pc.removeEventListener('signalingstatechange', onSignalingStateChange$);
        pc.removeEventListener('track', onTrack$);

        if (statsIntervalIdRef.value) {
            clearInterval(statsIntervalIdRef.value);
            statsIntervalIdRef.value = null;
        }
         if (connectionTimeoutRef.value) {
            clearTimeout(connectionTimeoutRef.value);
            connectionTimeoutRef.value = null;
        }

        // Stop video tracks associated with the connection
        const video = videoRef.value;
        if (video?.srcObject && video.srcObject instanceof MediaStream) {
            console.log("Stopping tracks during PC close - this IS the right place to stop tracks");
            
            // Here we SHOULD stop all tracks as the connection is being terminated
            const tracks = video.srcObject.getTracks();
            console.log(`Stopping ${tracks.length} tracks during peer connection close`);
            
            tracks.forEach(track => {
                console.log(`Stopping track: ${track.id}, kind: ${track.kind}, state: ${track.readyState}`);
                track.stop();
            });
            
            video.srcObject = null;
        }

        pc.close();
        peerConnectionRef.value = null; // Update the signal
        connected.value = false; // Ensure connected state is false
        videoIsPlayingRef.value = false; // Reset video playing state
        lastBytesReceivedRef.value = 0;

        console.log('Client: Peer connection closed');

        // Optionally trigger server-side stream closure
        if (triggerServerClose && streamId.value && sessionId.value) {
            serverCloseStream(streamId.value, sessionId.value).catch(err => {
                console.error("Client: Error during server close stream:", err);
            });
            streamId.value = "";
            sessionId.value = "";
        }
         // Ensure idle video plays after closing
        // Intenta reproducir el video de espera con retraso para dar tiempo a limpiar recursos
        setTimeout(() => {
            playIdleVideo$();
            console.log("Reproduciendo video de espera despuÃ©s de cerrar conexiÃ³n");
        }, 500);
    });

    const createPeerConnection$ = $(async (offer: RTCSessionDescriptionInit, iceServers: RTCIceServer[]) => {
        if (peerConnectionRef.value) {
            console.warn("Closing existing peer connection before creating new one.");
            closePC$(false); // Close client-side only first - Call QRL version
        }

        try {
            console.log("Client: Creating Peer Connection");
            const newPC = new RTCPeerConnection({ iceServers });

            // Use the QRL handlers
            newPC.addEventListener('icegatheringstatechange', onIceGatheringStateChange$);
            newPC.addEventListener('icecandidate', onIceCandidate$);
            newPC.addEventListener('iceconnectionstatechange', onIceConnectionStateChange$);
            newPC.addEventListener('connectionstatechange', onConnectionStateChange$);
            newPC.addEventListener('signalingstatechange', onSignalingStateChange$);
            newPC.addEventListener('track', onTrack$);

            console.log("Client: Setting remote description");
            await newPC.setRemoteDescription(offer); // Offer is already an object

            console.log("Client: Creating answer");
            const answer = await newPC.createAnswer();

            console.log("Client: Setting local description");
            await newPC.setLocalDescription(answer);

            peerConnectionRef.value = noSerialize(newPC); // Use noSerialize to prevent serialization issues
            return answer;

        } catch (error) {
            console.error('Client: Error creating peer connection:', error);
            peerConnectionRef.value = null; // Ensure ref is null on error
            throw error;
        }
    });

    const connect$ = $(async () => {
        if (connected.value || initiating.value) return; // Prevent multiple concurrent attempts

        initiating.value = true;
        connectionError.value = null;
        closePC$(false); // Close existing client-side connection if any, don't trigger server close yet - Call QRL version

        try {
            playIdleVideo$(); // Start with idle video - Call QRL version

            console.log("Client: Calling serverInitConnection");
            const { streamId: newStreamId, offer, iceServers, sessionId: newSessionId } = await serverInitConnection();

            streamId.value = newStreamId;
            sessionId.value = newSessionId;

            console.log("Client: Stream/Session IDs received:", newStreamId, newSessionId);
            console.log("Client: Creating peer connection with offer");
            const answer = await createPeerConnection$(offer, iceServers); // Call QRL version

            console.log("Client: Sending SDP answer via server");
            await serverSendSdpAnswer(newStreamId, newSessionId, answer);

            // Set connection timeout
             if (connectionTimeoutRef.value) clearTimeout(connectionTimeoutRef.value);
             connectionTimeoutRef.value = setTimeout(() => {
                if (!connected.value) {
                    console.error('Connection timeout - checking status');
                     const pc = peerConnectionRef.value; // Check current value
                     if (pc && (pc.iceConnectionState === 'checking' || pc.iceConnectionState === 'connected' || pc.iceConnectionState === 'completed')) {
                        console.log('Connection appears stable despite timeout - forcing connected state');
                        connected.value = true; // Force connected state if ICE seems okay
                        connectionError.value = null;
                    } else {
                        console.error('Connection truly timed out');
                        connectionError.value = "Connection timed out. Please try reconnecting.";
                        closePC$(true); // Close connection fully including server - Call QRL version
                    }
                }
            }, 15000); // 15 second timeout

            console.log("Client: Waiting for ICE connection...");

        } catch (error: any) {
            console.error('Client: Error during connection initialization:', error);
            connectionError.value = `Connection error: ${error.message || 'Unknown error'}`;
            closePC$(true); // Ensure full cleanup on error - Call QRL version
            connected.value = false;
            streamId.value = "";
            sessionId.value = "";
            
            // Ensure the video plays on error with a slight delay
            setTimeout(() => {
                playIdleVideo$(); // Retry playing idle video with a delay
                console.log("Attempting to play idle video after connection error");
            }, 1000);
        } finally {
            initiating.value = false;
        }
    });


    // --- Client-Side Effects (useVisibleTask$) ---

    // Initialize & Cleanup WebRTC / D-ID Connection
    useVisibleTask$(({ cleanup }) => {
        console.log("Inicializando componente de chat...");
        
        // Reproducir video de espera inmediatamente con reintento
        setTimeout(() => {
            playIdleVideo$();
            console.log("Primer intento de reproducir video de espera");
            
            // Reintento adicional por si acaso
            setTimeout(() => {
                if (!connected.value) {
                    playIdleVideo$();
                    console.log("Segundo intento de reproducir video de espera");
                }
            }, 2000);
        }, 500);
        
        // Intento de conexiÃ³n despuÃ©s de un retraso para asegurar que el DOM estÃ© listo
        setTimeout(() => {
            connect$();
        }, 1500);

        // Cleanup function when component unmounts
        cleanup(() => {
            console.log("Client: Cleanup running");
             closePC$(true); // Call the QRL function for full cleanup
             // Clear any other intervals/timeouts if necessary
             if (timerIntervalRef.value) clearInterval(timerIntervalRef.value);
             if (statsIntervalIdRef.value) clearInterval(statsIntervalIdRef.value);
             if (connectionTimeoutRef.value) clearTimeout(connectionTimeoutRef.value);
        });
    });

    // Load chat history on component initialization or when userId changes
    useVisibleTask$(async ({ track }) => { 
        track(() => initialData.value?.userId); // Re-run this effect if userId changes

        const currentUserId = initialData.value?.userId;

        // Clear chat history before loading new history or showing default messages.
        // This ensures that if a user logs out and another logs in, or if userId changes,
        // the old history is cleared immediately.
        chatHistory.splice(0, chatHistory.length);
        chatHistoryLoaded.value = false; // Reset loaded status

        if (!currentUserId) {
            console.log("[CHAT HISTORY] No user ID, showing default welcome message.");
            // Optionally, you could set loading.value here if you want a spinner
            chatHistory.push({
                role: "assistant",
                content: "Welcome! Please log in to see your chat history or start a new conversation."
            });
            chatHistoryLoaded.value = true;
            return;
        }
        
        console.log(`[CHAT HISTORY] Loading chat history for user: ${currentUserId}`);
        // Consider adding a loading state specific to chat history loading if it's slow
        // loading.value = true; // This is a general loading signal, might be okay for now

        try {
            const history = await serverLoadChatHistory(currentUserId);
            
            if (history && history.length > 0) {
                // Map all fields, including timestamp if available and used in UI
                const mappedHistory = history.map((msg: any) => ({
                    role: msg.role as 'user' | 'assistant' | 'system',
                    content: msg.content as string,
                    timestamp: msg.timestamp as string | undefined 
                }));
                chatHistory.splice(0, chatHistory.length, ...mappedHistory);
                console.log(`[CHAT HISTORY] Loaded ${history.length} messages for user ${currentUserId}.`);
            } else {
                console.log(`[CHAT HISTORY] No history found for user ${currentUserId}. Displaying welcome message.`);
                chatHistory.push({
                    role: "assistant",
                    content: "Welcome to the MOA chatbot! How can I help you today?"
                });
            }
        } catch (error) {
            console.error(`[CHAT HISTORY] Error loading chat history for user ${currentUserId}:`, error);
            // Ensure a message is present even on error
            chatHistory.push({
                role: "assistant",
                content: "Sorry, I couldn't load your chat history at the moment. Please try again later."
            });
        } finally {
            chatHistoryLoaded.value = true;
            // loading.value = false; // Reset general loading if it was set for history loading
        }
    });

    // Scroll chat to bottom on new message
    useVisibleTask$(({ track }) => {
        track(() => chatHistory.length);
        const chatEl = chatMessagesRef.value;
        if (chatEl) {
            // Delay scroll slightly to allow DOM update
            setTimeout(() => {
                chatEl.scrollTop = chatEl.scrollHeight;
            }, 50);
        }
    });

    // --- Event Handlers ($) ---

    const handleLanguageChange$ = $(async (event: Event) => {
        const newLang = (event.target as HTMLSelectElement).value;
        formValues.language = newLang;
        // Persist language preference to DB if user is logged in
        // Use optional chaining for safety
        if (initialData.value?.userId) {
           await serverUpdateUserLang(initialData.value.userId, newLang);
        }
    });

    const toggleMuteVideo$ = $(() => {
        muteVideo.value = !muteVideo.value;
        if (videoRef.value) {
            videoRef.value.muted = muteVideo.value;
        }
        console.log(`Video ${muteVideo.value ? 'muted' : 'unmuted'}`);
    });

    const handleReconnectClick$ = $(() => { // Now this can simply call the connect$ QRL
         console.log("Manual reconnect triggered");
         connect$(); // Call the refactored connect QRL
    });


    const startTalk$ = $(async (userInput: string) => {
        if (!userInput.trim()) return;

        loading.value = true;
        connectionError.value = null; // Clear previous errors on new interaction

        // Add user message immediately
        chatHistory.push({ role: 'user', content: userInput });
        if (inputRef.value) inputRef.value.value = ''; // Clear input field

        try {
            // 1. Get LangChain Response
            console.log("Client: Fetching LangChain response with chat history context");
            
            // Convert chat UI messages to format expected by LangChain
            const historyForLangChain = chatHistory.map(msg => ({
                role: msg.role,
                content: msg.content
            }));
            
            const botResponse = await serverFetchLangChainResponse(
                userInput,
                threadId.value,
                languageMap[formValues.language] || 'English',
                historyForLangChain
            );

            // Add assistant message
            chatHistory.push({ role: 'assistant', content: botResponse });

            // 2. Save to DB (fire and forget)
            // Use optional chaining for safety
            if (initialData.value?.userId) {
                serverSaveChatMessage(sessionId.value || 'no-session', userInput, botResponse, initialData.value.userId)
                    .catch(err => console.error("Client: Failed to save chat message:", err));
            }


            // 3. Create D-ID Talk (if not muted and connected)
            if (muteVideo.value) {
                console.log("Video muted, skipping talk creation.");
                loading.value = false;
                return;
            }

            // Ensure connection is ready
            if (!connected.value || !streamId.value || !sessionId.value) {
                console.warn("Not connected, attempting to connect before talk...");
                try {
                    // First try reconnecting
                    await connect$(); // Try to establish connection
                    await new Promise(resolve => setTimeout(resolve, 3000)); // Wait for connection to establish
                    
                    // Check again if we're connected
                    if (!connected.value || !streamId.value || !sessionId.value) {
                        console.error("Connection failed after reconnect attempt, cannot create talk.");
                        connectionError.value = "Connection failed. Cannot play response.";
                        loading.value = false;
                        return;
                    }
                    
                    console.log("Successfully reconnected, proceeding with talk creation");
                } catch (error) {
                    console.error("Error during reconnection attempt:", error);
                    connectionError.value = "Connection failed. Cannot play response.";
                    loading.value = false;
                    return;
                }
            }
            
            // Double check connection before proceeding
            if (!connected.value || !streamId.value || !sessionId.value) {
                console.error("Still not connected, cannot create talk.");
                connectionError.value = "Not connected. Cannot play response.";
                 loading.value = false;
                 return; // Don't proceed if not connected
            }
            console.log("Client: Creating talk");
            const voiceSettings = getVoiceSettings(formValues.language);
            await serverCreateTalk(botResponse, voiceSettings, streamId.value, sessionId.value);
            console.log("Client: Talk request sent");
            
            // Ensure we're properly monitoring for the talk video stream
            if (peerConnectionRef.value && videoRef.value) {
                console.log("Setting up enhanced talk stream detection");
                
                // Reset detection variables
                videoIsPlayingRef.value = false;
                lastBytesReceivedRef.value = 0;
                // Clear any existing stats interval
                if (statsIntervalIdRef.value) {
                    clearInterval(statsIntervalIdRef.value);
                    statsIntervalIdRef.value = null;
                }
                
                // Add a more frequent check specifically for talk stream
                const pc = peerConnectionRef.value;
                statsIntervalIdRef.value = setInterval(async () => {
                    if (!pc || pc.connectionState !== 'connected') {
                        if (statsIntervalIdRef.value) {
                            clearInterval(statsIntervalIdRef.value);
                            statsIntervalIdRef.value = null;
                        }
                        return;
                    }
                    
                    try {
                        // Get all active tracks first
                        const receivers = pc.getReceivers();
                        const activeVideoTracks = receivers
                            .filter((receiver: RTCRtpReceiver) => receiver.track &&
                                   receiver.track.kind === 'video' &&
                                   receiver.track.readyState === 'live')
                            .map((receiver: RTCRtpReceiver) => receiver.track);
                        
                        console.log(`Found ${activeVideoTracks.length} active video tracks`);
                        
                        // Only proceed with stats if we have video tracks
                        if (activeVideoTracks.length > 0) {
                            // Get detailed stats to check if we're receiving actual data
                            const stats = await pc.getStats();
                            let hasActiveVideoData = false;
                            let currentBytesReceived = 0;
                            
                            // Parse stats to check for active video data flow
                            stats.forEach((report: RTCStats) => {
                                if (report.type === 'inbound-rtp' &&
                                    'mediaType' in report &&
                                    report.mediaType === 'video') {
                                    
                                    currentBytesReceived = 'bytesReceived' in report ?
                                        report.bytesReceived as number : 0;
                                    
                                    // Check if bytes are increasing, indicating active data
                                    hasActiveVideoData = currentBytesReceived > lastBytesReceivedRef.value &&
                                                       currentBytesReceived > 0;
                                    
                                    if (hasActiveVideoData && !videoIsPlayingRef.value) {
                                        console.log("Talk video stream now active with data flow");
                                        videoIsPlayingRef.value = true;
                                        
                                        // Create fresh stream with all active tracks
                                        const allActiveTracks = receivers
                                            .filter((r: RTCRtpReceiver) => r.track && r.track.readyState === 'live')
                                            .map((r: RTCRtpReceiver) => r.track);
                                        
                                        const refreshedStream = new MediaStream(allActiveTracks);
                                        onVideoStatusChange$(true, refreshedStream);
                                    }
                                    
                                    // Update for next comparison
                                    lastBytesReceivedRef.value = currentBytesReceived;
                                }
                            });
                            
                            // Handle case where video should be playing but no data is flowing
                            if (!hasActiveVideoData && videoIsPlayingRef.value && !loading.value) {
                                console.log("Talk video stream has no active data flow, reverting to idle");
                                videoIsPlayingRef.value = false;
                                onVideoStatusChange$(false, null);
                            }
                        } else if (videoIsPlayingRef.value && !loading.value) {
                            // No active video tracks but we think we're playing
                            console.log("No active video tracks found, reverting to idle");
                            videoIsPlayingRef.value = false;
                            onVideoStatusChange$(false, null);
                        }
                    } catch (error) {
                        console.error("Error monitoring video stream:", error);
                    }
                }, 750); // Slightly more frequent checking for smoother transitions
                // Initial check for active tracks
                const initialReceivers = pc.getReceivers();
                const initialVideoTracks = initialReceivers
                    .filter((receiver: RTCRtpReceiver) => receiver.track &&
                            receiver.track.kind === 'video' &&
                            receiver.track.readyState === 'live')
                    .map((receiver: RTCRtpReceiver) => receiver.track);
                
                // Setup interval to check for talk stream activation
                const talkStreamCheckInterval = setInterval(() => {
                    if (initialVideoTracks.length > 0) {
                        console.log(`Initial check: Found ${initialVideoTracks.length} active video tracks`);
                    
                    // Make sure all video tracks are enabled
                    initialVideoTracks.forEach((track: MediaStreamTrack) => {
                        console.log(`Ensuring video track is enabled: ${track.id}`);
                        track.enabled = true;
                    });
                    
                    // Get all active tracks (video and audio)
                    const allActiveTracks = initialReceivers
                        .filter((receiver: RTCRtpReceiver) => receiver.track && receiver.track.readyState === 'live')
                        .map((receiver: RTCRtpReceiver) => receiver.track);
                    
                    // Create a new stream with all active tracks
                    try {
                        const mediaStream = new MediaStream(allActiveTracks);
                        
                        // Set directly to video element without stopping tracks
                        const video = videoRef.value;
                        if (video) {
                            // Check if we need to update the video element
                            const needsUpdate = !video.srcObject ||
                                (video.srcObject as MediaStream).getVideoTracks().length === 0 ||
                                (video.srcObject as MediaStream).getVideoTracks()[0].readyState !== 'live';
                            if (needsUpdate) {
                                console.log("Updating video element with active stream");
                            
                            // Direct assignment without stopping tracks
                            video.srcObject = mediaStream;
                            video.muted = muteVideo.value;
                            video.style.display = 'block';
                            
                            // Play the video
                            video.play().catch(e => {
                                console.error('Error playing video:', e);
                                if (e.name === 'NotAllowedError') {
                                    video.muted = true;
                                    video.play().catch(e2 => {
                                        console.error('Still cannot play video:', e2);
                                    });
                                }
                            });
                            }
                        }
                        } catch (err) {
                            console.error("Error creating media stream:", err);
                        }
                    }
                }, 300); // Check very frequently for talk stream activation
            }
            
        } catch (error: any) {
            console.error("Client: Error during startTalk:", error);
            chatHistory.push({ role: 'assistant', content: `Error: ${error.message || 'Could not process request.'}` });
            connectionError.value = `Error: ${error.message || 'Could not process request.'}`;
            // Attempt to play idle video on error to reset visual state
            if (videoRef.value) {
                playIdleVideo$();
            }
        } finally {
            loading.value = false;
        }
    });

    const handleSendClick$ = $(() => {
        if (inputRef.value && inputRef.value.value.trim()) {
            startTalk$(inputRef.value.value);
        }
    });

    const handleKeyUp$ = $((event: KeyboardEvent) => {
        if (event.key === 'Enter' && inputRef.value && inputRef.value.value.trim()) {
            startTalk$(inputRef.value.value);
        }
    });

    // --- Audio Recording ---
    
    // Define processAudio$ first, before it's used in event listeners
    const processAudio$ = $(async (audioBlob: Blob) => {
        loading.value = true; // Indicate processing
        
        // Mostrar mensaje de retroalimentaciÃ³n en la interfaz
        chatHistory.push({
            role: 'assistant',
            content: `Procesando grabaciÃ³n de voz en ${getLanguageCode(formValues.language)} ${languageMap[formValues.language] || 'English'}...`
        });
        
        try {
            // Convert Blob to base64 string for easier serialization
            const arrayBuffer = await audioBlob.arrayBuffer();
            const base64Audio = btoa(
                new Uint8Array(arrayBuffer)
                    .reduce((data, byte) => data + String.fromCharCode(byte), '')
            );
            
            console.log("Client: Audio converted to base64, size:", base64Audio.length);
            console.log(`Client: Processing voice recording in ${formValues.language} (${languageMap[formValues.language] || 'English'})`);
            
            // Send the base64 string to the server along with mime type
            // Eliminar el Ãºltimo mensaje si es el de procesamiento
            if (chatHistory.length > 0 &&
                chatHistory[chatHistory.length - 1].role === 'assistant' &&
                chatHistory[chatHistory.length - 1].content.startsWith('Procesando grabaciÃ³n de voz')) {
                chatHistory.pop();
            }
            
            const transcription = await serverProcessAudio(
                base64Audio,
                audioBlob.type,  // Pass the mime type
                languageMap[formValues.language] || 'English'
            );

            if (transcription && !transcription.startsWith("Error:")) {
                // Mostrar la transcripciÃ³n antes de la respuesta
                console.log(`Client: Transcription successful in ${formValues.language}: "${transcription}"`);
                
                // AÃ±adir mensaje con la transcripciÃ³n y desencadenar respuesta AI
                await startTalk$(transcription);
            } else {
                console.error(`Client: Transcription failed in ${formValues.language}:`, transcription);
                
                // Mensaje de error mÃ¡s detallado para el usuario
                chatHistory.push({
                    role: 'assistant',
                    content: `No pude procesar correctamente el audio en ${languageMap[formValues.language] || 'English'}. Por favor, intenta de nuevo o escribe tu mensaje.`
                });
            }
        } catch (error: any) {
            console.error(`Client: Error processing audio in ${formValues.language}:`, error);
            
            // Eliminar el mensaje de procesamiento si existe
            if (chatHistory.length > 0 &&
                chatHistory[chatHistory.length - 1].role === 'assistant' &&
                chatHistory[chatHistory.length - 1].content.startsWith('Procesando grabaciÃ³n de voz')) {
                chatHistory.pop();
            }
            
            // Mensaje de error mÃ¡s amigable y especÃ­fico para el idioma
            const errorMsg = `Lo siento, hubo un problema procesando tu grabaciÃ³n en ${getLanguageCode(formValues.language)} ${languageMap[formValues.language]}. ${error.message}`;
            chatHistory.push({ role: 'assistant', content: errorMsg });
        } finally {
            loading.value = false;
        }
    });
    
    const startRecording$ = $(async () => {
        if (isRecording.value) return;

        try {
            // ConfiguraciÃ³n de audio optimizada para reconocimiento de voz
            const audioConstraints = {
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true,
                    sampleRate: 48000
                }
            };
            
            console.log(`Client: Starting voice recording for language: ${formValues.language} (${languageMap[formValues.language] || 'English'})`);
            
            const stream = await navigator.mediaDevices.getUserMedia(audioConstraints);
            
            // Intentar usar audio/webm;codecs=opus para mejor calidad, con fallback a audio/webm
            let mimeType = 'audio/webm;codecs=opus';
            if (!MediaRecorder.isTypeSupported(mimeType)) {
                mimeType = 'audio/webm';
                console.log('Client: Opus codec not supported, using standard audio/webm');
            }
            
            const mediaRecorder = new MediaRecorder(stream, {
                mimeType: mimeType,
                audioBitsPerSecond: 128000
            });
            recorderRef.value = noSerialize(mediaRecorder);

            const audioChunks: Blob[] = [];

            mediaRecorder.addEventListener("dataavailable", (event) => {
                audioChunks.push(event.data);
            });

            mediaRecorder.addEventListener("stop", async () => {
                const audioBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType });
                
                // Log video tracks to help with debugging
                console.log("Found", stream.getVideoTracks().length, "active video tracks");
                
                // Stop all tracks
                stream.getTracks().forEach(track => track.stop());
                
                // Update state
                isRecording.value = false;
                recorderRef.value = null;
                
                // Clear timer
                if (timerIntervalRef.value) clearInterval(timerIntervalRef.value);
                recordingTime.value = 0;

                // Process audio if we have data
                if (audioBlob.size > 0) {
                    await processAudio$(audioBlob);
                } else {
                    console.log("Empty recording, skipping processing.");
                }
            });

            mediaRecorder.start();
            isRecording.value = true;
            recordingTime.value = 0; // Reset timer
            if (timerIntervalRef.value) clearInterval(timerIntervalRef.value); // Clear previous interval
            timerIntervalRef.value = setInterval(() => {
                recordingTime.value++;
            }, 1000);

            // Auto-stop after 30 seconds
            setTimeout(() => {
                if (mediaRecorder.state === 'recording') {
                    mediaRecorder.stop();
                }
            }, 30000);

        } catch (error) {
            console.error("Error starting recording:", error);
            isRecording.value = false;
            alert("Could not start recording. Please ensure microphone permission is granted.");
        }
    });

    const stopRecording$ = $(() => {
        if (recorderRef.value && recorderRef.value.state === 'recording') {
            recorderRef.value.stop();
            // State changes (isRecording=false, etc.) handled in 'stop' event listener
        }
         if (timerIntervalRef.value) {
            clearInterval(timerIntervalRef.value);
            timerIntervalRef.value = null;
        }
    });

    const toggleRecording$ = $(() => {
        if (isRecording.value) {
            stopRecording$();
        } else {
            startRecording$();
        }
    });


    // --- Render ---
    useVisibleTask$(() => {
        // Ajuste dinÃ¡mico del layout con cÃ¡lculo preciso para evitar scroll
        const adjustLayout = () => {
            const vh = window.innerHeight;
            const vw = window.innerWidth;
            
            // CÃ¡lculo mÃ¡s preciso para prevenir scroll
            const navbarHeight = 58;
            // Margen de seguridad adicional para evitar scrollbar
            const safetyMargin = 10;
            // Footer/input height mÃ¡s el padding/margin
            const bottomHeight = 5;
            
            // Altura disponible real con todos los mÃ¡rgenes necesarios
            const availableHeight = vh - navbarHeight - safetyMargin - bottomHeight;
            
            // Ajuste proporciones para que encaje perfectamente sin scroll
            const videoHeight = Math.floor(availableHeight * 0.38);
            const chatHeight = availableHeight - videoHeight;
            
            // Variables CSS para el layout completo
            document.documentElement.style.setProperty('--vh', `${vh}px`);
            document.documentElement.style.setProperty('--vw', `${vw}px`);
            document.documentElement.style.setProperty('--available-height', `${availableHeight}px`);
            document.documentElement.style.setProperty('--video-height', `${videoHeight}px`);
            document.documentElement.style.setProperty('--chat-height', `${chatHeight}px`);
            
            // Ajustes de tamaÃ±o para elementos UI basados en el ancho
            const inputHeight = Math.max(32, Math.min(40, Math.floor(vw * 0.03)));
            document.documentElement.style.setProperty('--input-height', `${inputHeight}px`);
        };
        
        // Ejecutar al cargar y cuando cambie el tamaÃ±o
        adjustLayout();
        window.addEventListener('resize', adjustLayout);
        return () => window.removeEventListener('resize', adjustLayout);
    });
    
    return (
        <div class="chat-container" style={{ height: 'var(--available-height, 70vh)' }}>

            {/* Video Panel - Similar a la imagen de referencia */}
            <div class="video-panel">
                <video
                    ref={videoRef}
                    id="talk-video"
                    autoplay
                    playsInline
                    muted={muteVideo.value}
                    class="video-element"
                    preload="auto"
                />
                
                {loading.value && (
                    <div class="video-processing-indicator">
                        <Spinner />
                        <span>Processing...</span>
                    </div>
                )}
                
                {initiating.value && (
                    <div class="video-connecting-overlay">
                        <Spinner />
                        <p>Connecting to Avatar...</p>
                    </div>
                )}
                
                {/* Control Panel - Minimalista como en la imagen */}
                <div class="control-panel">
                    <div class="control-left">
                        {/* Language selection with country codes */}
                        <div class="language-icons">
                            {languages.map((option) => (
                                <button
                                    key={option.value}
                                    onClick$={async () => {
                                        formValues.language = option.value;
                                        if (initialData.value?.userId) {
                                            await serverUpdateUserLang(initialData.value.userId, option.value);
                                        }
                                    }}
                                    class={`lang-icon-btn ${formValues.language === option.value ? 'active' : ''}`}
                                    title={option.label}
                                    aria-label={option.label}
                                    dangerouslySetInnerHTML={option.flagSvg}
                                >
                                </button>
                            ))}
                        </div>
                    </div>
                    
                    <div class="control-right">
                        {!connected.value && !initiating.value && (
                            <button
                                onClick$={handleReconnectClick$}
                                class="connect-button">
                                Connect
                            </button>
                        )}
                    </div>
                </div>
            </div>

            {/* Chat Panel - Limpio y elegante como en la imagen */}
            <div class="chat-panel">
                {/* Header similar a la imagen */}
              
                
                {/* Mensajes de Chat */}
                <div
                    ref={chatMessagesRef}
                    class="chat-messages">
                    {chatHistory.map((message, index) => (
                        <div
                            key={index}
                            class={`message-container ${message.role === 'user' ? 'user-message' : 'assistant-message'}`}>
                            <div class={`message-bubble ${message.role === 'user' ? 'user-bubble' : 'assistant-bubble'}`}>
                                <div class="message-sender">
                                    {message.role === 'user' ? 'You' : 'Assistant'}
                                </div>
                                <p class="message-content">{message.content}</p>
                            </div>
                        </div>
                    ))}
                    
                    {loading.value && chatHistory[chatHistory.length - 1]?.role === 'user' && (
                        <div class="message-container assistant-message">
                            <div class="message-bubble assistant-bubble">
                                <div class="message-sender">Assistant</div>
                                <div class="typing-indicator"><span></span><span></span><span></span></div>
                            </div>
                        </div>
                    )}
                    </div>

                {/* Input Area - Fixed at bottom on mobile */}
                <div class="chat-input-container fixed-mobile-input">
                    <div class="chat-input-wrapper">
                        <button
                            onClick$={toggleMuteVideo$}
                            class="volume-button control-btn"
                            aria-label={muteVideo.value ? 'Unmute Video' : 'Mute Video'}>
                            {muteVideo.value ? <LuVolumeX class="w-4 h-4" /> : <LuVolume2 class="w-4 h-4" />}
                        </button>
                        
                        {/* Language icons hidden on mobile (moved to top panel) */}
                        <div class="language-icons desktop-only">
                            {languages.map((option) => (
                                <button
                                    key={option.value}
                                    onClick$={async () => {
                                        formValues.language = option.value;
                                        if (initialData.value?.userId) {
                                            await serverUpdateUserLang(initialData.value.userId, option.value);
                                        }
                                    }}
                                    class={`lang-icon-btn ${formValues.language === option.value ? 'active' : ''}`}
                                    title={option.label}
                                    aria-label={option.label}
                                    dangerouslySetInnerHTML={option.flagSvg}
                                >
                                </button>
                            ))}
                        </div>
                        
                        <button
                            onClick$={toggleRecording$}
                            disabled={initiating.value || loading.value}
                            class={`mic-button ${isRecording.value ? 'recording' : ''}`}
                            aria-label={isRecording.value ? 'Stop Recording' : 'Start Recording'}>
                            {isRecording.value ? <LuMic class="w-4 h-4" /> : <LuMicOff class="w-4 h-4" />}
                        </button>
                        
                        <input
                            ref={inputRef}
                            onKeyUp$={handleKeyUp$}
                            type="text"
                            placeholder={initiating.value ? "Connecting..." : "Type a message..."}
                            disabled={initiating.value || loading.value}
                            class="chat-input"
                        />
                        
                        <button
                            onClick$={handleSendClick$}
                            disabled={initiating.value || loading.value}
                            class="send-button">
                            {loading.value ? <Spinner size="small" /> : <LuSend class="w-4 h-4" />}
                        </button>
                    </div>
                </div>
            </div>
        </div>
    );
});

// Spinner component kept as is, since it's a custom animated component
export const Spinner = component$<{ size?: 'small' | 'medium' }>(({ size = 'medium' }) => {
    const sizeClass = size === 'small' ? 'w-4 h-4 border-2' : 'w-5 h-5 border-[3px]';
    return <div class={`animate-spin rounded-full ${sizeClass} border-white border-t-transparent`} role="status" aria-label="loading"></div>;
});


// --- Styles ---
export const STYLES = `
@keyframes spin {
  to { transform: rotate(360deg); }
}
.animate-spin {
  animation: spin 1s linear infinite;
}

@keyframes bubble-appear {
  from { opacity: 0; transform: translateY(10px) scale(0.95); }
  to { opacity: 1; transform: translateY(0) scale(1); }
}
.animate-bubble-appear {
  animation: bubble-appear 0.3s ease forwards;
}

.typing-indicator span {
  width: 5px;
  height: 5px;
  background-color: currentColor;
  border-radius: 50%;
  display: inline-block;
  margin: 0 1px;
  animation: typing-bounce 1.2s infinite ease-in-out;
}
.typing-indicator span:nth-child(2) { animation-delay: 0.15s; }
.typing-indicator span:nth-child(3) { animation-delay: 0.3s; }

@keyframes typing-bounce {
  0%, 80%, 100% { transform: scale(0); }
  40% { transform: scale(1.0); }
}

@keyframes pulse {
  0%, 100% { opacity: 1; transform: scale(1); }
  50% { opacity: 0.7; transform: scale(1.05); }
}
.animate-pulse {
    animation: pulse 1.5s cubic-bezier(0.4, 0, 0.6, 1) infinite;
}

@keyframes fade-in {
  from { opacity: 0; transform: translateY(5px); }
  to { opacity: 1; transform: translateY(0); }
}
.animate-fade-in {
    animation: fade-in 0.3s ease-out forwards;
}

/* Custom scrollbar (optional) */
/* Ensure the app takes exactly the viewport size */
html, body {
  margin: 0;
  padding: 0;
  height: 100vh;
  width: 100vw;
}

/* Estilos CSS para el nuevo diseÃ±o limpio y minimalista */
/* Base Styles */
html, body {
  margin: 0;
  padding: 0;
  height: 100%;
  width: 100%;
  overflow: hidden;
  font-family: 'Poppins', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
  -webkit-font-smoothing: antialiased;
}

/* Main Container */
.chat-container {
  display: flex;
  flex-direction: column;
  width: 100%;
  background-color: #f8f9fa;
  overflow: hidden;
}

/* Video Panel */
.video-panel {
  width: 100%;
  position: relative;
  height: var(--video-height, 40vh);
  background-color: #000;
  box-shadow: 0 1px 3px rgba(0,0,0,0.1);
}

.video-element {
  width: 100%;
  height: 100%;
  object-fit: cover;
}

.control-panel {
  position: absolute;
  bottom: 0;
  left: 0;
  right: 0;
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 8px 10px;
  background-color: rgba(255, 255, 255, 0.9);
}

.control-left, .control-right {
  display: flex;
  align-items: center;
}

/* Adjust language icons in control panel for mobile */
.control-left .language-icons {
  display: flex;
  gap: 4px;
}

.volume-button {
  width: 30px;
  height: 30px;
  display: flex;
  justify-content: center;
  align-items: center;
  border-radius: 50%;
  background-color: #eaeaea;
  border: none;
  margin-right: 10px;
  cursor: pointer;
}

.language-selector {
  height: 30px;
  padding: 0 10px;
  border-radius: 4px;
  border: 1px solid #e0e0e0;
  background-color: white;
  font-size: 14px;
}

.connect-button {
  padding: 6px 16px;
  background-color: #0cd15b;
  color: white;
  border: none;
  border-radius: 4px;
  font-size: 14px;
  cursor: pointer;
}

/* Chat Panel */
.chat-panel {
  flex-grow: 1;
  height: var(--chat-height, 50vh);
  background-color: white;
  display: flex;
  flex-direction: column;
}

.chat-header {
  padding: 12px 16px;
  background-color: #f1f1f4;
  border-bottom: 1px solid #e0e0e0;
}

.chat-header-info {
  display: flex;
  flex-direction: column;
}

.chat-title {
  font-weight: 500;
  color: #333;
  font-size: 15px;
}

.chat-subtitle {
  font-size: 12px;
  color: #666;
  margin-top: 3px;
}

.chat-messages {
  flex-grow: 1;
  overflow-y: auto;
  padding: 16px;
  display: flex;
  flex-direction: column;
  gap: 16px;
}

.message-container {
  display: flex;
}

.user-message {
  justify-content: flex-end;
}

.assistant-message {
  justify-content: flex-start;
}

.message-bubble {
  max-width: 80%;
  padding: 10px 14px;
  border-radius: 18px;
  box-shadow: 0 1px 2px rgba(0,0,0,0.1);
  animation: bubble-appear 0.2s ease-out;
}

.user-bubble {
  background-color: #1a85ff;
  color: white;
  border-bottom-right-radius: 4px;
}

.assistant-bubble {
  background-color: #f1f1f4;
  color: #333;
  border-bottom-left-radius: 4px;
}

.message-sender {
  font-size: 11px;
  margin-bottom: 4px;
  opacity: 0.8;
  font-weight: 500;
}

.message-content {
  font-size: 14px;
  line-height: 1.4;
  white-space: pre-wrap;
  word-break: break-word;
}

/* Input Area */
.chat-input-container {
  padding: 12px 16px;
  border-top: 1px solid #e0e0e0;
}

/* Fixed Mobile Input */
.fixed-mobile-input {
  position: relative;
}

/* Fixed position for mobile */
@media (max-width: 767px) {
  .fixed-mobile-input {
    position: fixed;
    bottom: 0;
    left: 0;
    right: 0;
    background-color: #f8f9fa;
    padding: 10px 16px;
    z-index: 20;
    border-top: 1px solid #e0e0e0;
    box-shadow: 0 -2px 10px rgba(0,0,0,0.05);
  }
  
  /* Add padding at the bottom of chat messages to prevent overlap with fixed input */
  .chat-messages {
    padding-bottom: 70px !important;
  }
}

.chat-input-wrapper {
  display: flex;
  align-items: center;
  background-color: white;
  width: 100%;
  border-radius: 24px;
  border: 1px solid #e0e0e0;
  padding: 0 6px;
  height: 42px;
}

.control-btn {
  width: 32px;
  height: 32px;
  display: flex;
  justify-content: center;
  align-items: center;
  background: none;
  border: none;
  color: #666;
  cursor: pointer;
}

.mic-button {
  width: 32px;
  height: 32px;
  display: flex;
  justify-content: center;
  align-items: center;
  background: none;
  border: none;
  color: #666;
  cursor: pointer;
}

.language-icons {
  display: flex;
  gap: 2px;
  margin: 0 2px;
}

/* This space intentionally left blank - removing obsolete CSS */

.lang-icon-btn {
  width: 36px;
  height: 36px;
  border: none;
  background: #f0f0f0;
  border-radius: 4px;
  cursor: pointer;
  padding: 2px;
  display: flex;
  align-items: center;
  justify-content: center;
  overflow: hidden;
  transition: transform 0.2s ease;
}

/* Control panel language icons should be slightly smaller */
.control-left .lang-icon-btn {
  width: 34px;
  height: 24px;
  border-radius: 3px;
}

.lang-icon-btn:hover {
  transform: scale(1.05);
}

.lang-icon-btn.active {
  box-shadow: 0 0 0 2px #1a85ff, 0 0 0 4px rgba(26, 133, 255, 0.3);
}

/* SVG flag styling */
.lang-icon-btn svg {
  width: 100%;
  height: 100%;
  object-fit: cover;
}

.mic-button.recording {
  color: #f44336;
  animation: pulse 1.5s infinite;
}

.chat-input {
  flex-grow: 1;
  height: 100%;
  border: none;
  padding: 0 8px;
  font-size: 14px;
}

.chat-input:focus {
  outline: none;
}

.send-button {
  min-width: 32px;
  width: 32px;
  height: 32px;
  display: flex;
  justify-content: center;
  align-items: center;
  background-color: #1a85ff;
  color: white;
  border: none;
  border-radius: 50%;
  cursor: pointer;
}

/* Loading and Status Indicators */
.typing-indicator {
  display: flex;
  gap: 4px;
  padding: 4px 0;
}

.typing-indicator span {
  width: 6px;
  height: 6px;
  border-radius: 50%;
  background: #888;
  animation: typing 1.4s infinite both;
}

.typing-indicator span:nth-child(2) {
  animation-delay: 0.2s;
}

.typing-indicator span:nth-child(3) {
  animation-delay: 0.4s;
}

.video-processing-indicator {
  position: absolute;
  right: 10px;
  bottom: 60px;
  background-color: rgba(0,0,0,0.7);
  color: white;
  padding: 6px 12px;
  border-radius: 16px;
  display: flex;
  align-items: center;
  gap: 6px;
  font-size: 12px;
}

.video-connecting-overlay {
  position: absolute;
  inset: 0;
  background-color: rgba(0,0,0,0.7);
  display: flex;
  flex-direction: column;
  align-items: center;
  justify-content: center;
  color: white;
  gap: 10px;
}

/* Animations */
@keyframes bubble-appear {
  from { opacity: 0; transform: translateY(5px); }
  to { opacity: 1; transform: translateY(0); }
}

@keyframes pulse {
  0% { opacity: 1; }
  50% { opacity: 0.6; }
  100% { opacity: 1; }
}

@keyframes typing {
  0% { transform: translateY(0); }
  50% { transform: translateY(-5px); }
  100% { transform: translateY(0); }
}
/* Responsive Adjustments */
@media (min-width: 768px) {
  .chat-container {
    flex-direction: row;
  }
  
  .video-panel {
    width: 40%;
    height: var(--available-height, 90vh);
  }
  
  .chat-panel {
    width: 60%;
    height: var(--available-height, 100vh);
  }
  
  .control-panel {
    height: 40px;
  }
  
  .chat-input-wrapper {
    max-width: 90%;
    margin: 0 auto;
  }
  
  /* Reset fixed position for desktop */
  .fixed-mobile-input {
    position: relative;
    box-shadow: none;
  }
  
  /* Show language icons in input area only on desktop */
  .desktop-only {
    display: flex;
  }
}

/* Hide on mobile */
.desktop-only {
  display: none;
}

/* Hide scrollbars but maintain functionality */
.chat-messages::-webkit-scrollbar {
  width: 4px;
}

.chat-messages::-webkit-scrollbar-track {
  background: transparent;
}

.chat-messages::-webkit-scrollbar-thumb {
  background: rgba(0,0,0,0.1);
  border-radius: 10px;
  overflow: hidden;
}

/* Hide scrollbars on main layout */
.h-screen.w-screen.max-w-full {
  overflow: hidden;
}

.overflow-y-auto::-webkit-scrollbar {
  width: 3px;
}
.overflow-y-auto::-webkit-scrollbar-track {
  background: rgba(0,0,0,0.05);
  border-radius: 10px;
}
.overflow-y-auto::-webkit-scrollbar-thumb {
  background: rgba(0,0,0,0.2);
  border-radius: 10px;
}
.overflow-y-auto::-webkit-scrollbar-thumb:hover {
  background: rgba(0,0,0,0.3);
}

/* Responsive adjustments */
@media (max-width: 768px) {
  .overflow-y-auto::-webkit-scrollbar {
    width: 3px;
  }
}
`;

